{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import operator as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math, itertools\n",
    "import statistics\n",
    "import json\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from operator import itemgetter\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, accuracy_score\n",
    "from collections import Counter\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def load_file(data_file_path):\n",
    "    data_df = pd.read_csv(data_file_path, delimiter=\";\")\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45173, 10)\n"
     ]
    }
   ],
   "source": [
    "# Pull and filter all calls <= 20.\n",
    "max_calls = 32\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "mkt_df_filtered = mkt_df_filtered[['job', 'marital', 'education', 'default', 'housing', 'loan', 'age', 'balance', 'campaign', 'y']]\n",
    "print(mkt_df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   job  marital  education  default  housing  loan  age  balance  campaign  y\n",
      "0    4        1          2        0        1     0   58     2143         1  0\n",
      "1    9        2          1        0        1     0   44       29         1  0\n",
      "2    2        1          1        0        1     1   33        2         1  0\n",
      "3    1        1          3        0        1     0   47     1506         1  0\n",
      "4   11        2          3        0        0     0   33        1         1  0\n",
      "5    4        1          2        0        1     0   35      231         1  0\n",
      "6    4        2          2        0        1     1   28      447         1  0\n",
      "7    2        0          2        1        1     0   42        2         1  0\n",
      "8    5        1          0        0        1     0   58      121         1  0\n",
      "9    9        2          1        0        1     0   43      593         1  0\n"
     ]
    }
   ],
   "source": [
    "# We use the LabelEncoder from SkLearn to transform the following features.\n",
    "features_to_transform = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'y']\n",
    "for feature in features_to_transform:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(mkt_df_filtered[feature])\n",
    "    mkt_df_filtered[feature] = le.transform(mkt_df_filtered[feature])\n",
    "\n",
    "# For obtaining the best hyper-parameters.\n",
    "print(mkt_df_filtered.head(10))\n",
    "y = mkt_df_filtered['campaign']\n",
    "X = mkt_df_filtered.drop(columns=['campaign'])\n",
    "\n",
    "# Double checking .\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "fold_data = []\n",
    "\n",
    "for train_index, test_index in kf.split(mkt_df_filtered):\n",
    "    fold_data.append((train_index, test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  87.95863909272849\n",
      "Accuracy is:  87.95863909272849\n",
      "Accuracy is:  87.95863909272849\n",
      "Accuracy is:  87.95863909272849\n",
      "[]\n",
      "\n",
      "\n",
      "Accuracy is:  88.3033133199911\n",
      "Accuracy is:  88.3033133199911\n",
      "Accuracy is:  88.3033133199911\n",
      "Accuracy is:  88.3033133199911\n",
      "[]\n",
      "\n",
      "\n",
      "Accuracy is:  88.25753363727344\n",
      "Accuracy is:  88.25753363727344\n",
      "Accuracy is:  88.25753363727344\n",
      "Accuracy is:  88.25753363727344\n",
      "[]\n",
      "\n",
      "\n",
      "Accuracy is:  87.94618036250417\n",
      "Accuracy is:  87.94618036250417\n",
      "Accuracy is:  87.94618036250417\n",
      "Accuracy is:  87.94618036250417\n",
      "[]\n",
      "\n",
      "\n",
      "Accuracy is:  88.12409651951518\n",
      "Accuracy is:  88.12409651951518\n",
      "Accuracy is:  88.12409651951518\n",
      "Accuracy is:  88.12409651951518\n",
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decisoon Tree\n",
    "\n",
    "for tt_split in fold_data:\n",
    "    \n",
    "    train_index = tt_split[0]\n",
    "    test_index = tt_split[1]\n",
    "    \n",
    "    # Pull data for train test split.\n",
    "    train_df = mkt_df_filtered.iloc[train_index]\n",
    "    test_df = mkt_df_filtered.iloc[test_index]\n",
    "    \n",
    "    # Split train and test dataframes into input and output.\n",
    "    train_y = train_df['y']\n",
    "    train_x = train_df.drop(columns=['y'])\n",
    "    test_y = test_df['y']\n",
    "    test_x = test_df.drop(columns=['y'])\n",
    "    \n",
    "    # max_depths = [i for i in range(1, 21)]\n",
    "    # Thus far, max depths = 20 gives best results.\n",
    "    \n",
    "    mids = [0.5, 1, 2, 5]\n",
    "    \n",
    "    results_fold = []\n",
    "    \n",
    "    for el in mids:\n",
    "    \n",
    "        # Instantiate the Decision Tree Classifier.\n",
    "        model = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split = 500)\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        # Obtain predictions for the test set.\n",
    "        predictions = model.predict(test_x)\n",
    "        \n",
    "        # Calls persons based on predications. Note the number of success and calls.\n",
    "        total_s = 0\n",
    "        total_c = 0\n",
    "        t_s = [0]\n",
    "        t_c = [0]\n",
    "        \n",
    "#         for loc, pred in enumerate(predictions):\n",
    "#             real = test_df.iloc[loc]\n",
    "#             if pred > real['campaign']:\n",
    "#                 total_c += int(pred)\n",
    "#             else:\n",
    "#                 if real['y'] == 1:\n",
    "#                     total_s += 1\n",
    "#                 total_c += int(pred)\n",
    "#             t_s.append(total_s)\n",
    "#             t_c.append(total_c)\n",
    "        \n",
    "#         results_fold.append(metrics.auc(t_c, t_s))\n",
    "        \n",
    "        acc_score = accuracy_score(test_y, predictions)*100\n",
    "        print(\"Accuracy is: \", acc_score)\n",
    "        \n",
    "    print(results_fold)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "for tt_split in fold_data:\n",
    "    \n",
    "    train_index = tt_split[0]\n",
    "    test_index = tt_split[1]\n",
    "    \n",
    "    # Pull data for train test split.\n",
    "    train_df = mkt_df_filtered.iloc[train_index]\n",
    "    test_df = mkt_df_filtered.iloc[test_index]\n",
    "    \n",
    "    # Split train and test dataframes into input and output.\n",
    "    train_y = train_df['y']\n",
    "    train_x = train_df.drop(columns=['y'])\n",
    "    test_y = test_df['y']\n",
    "    test_x = test_df.drop(columns=['y'])\n",
    "    \n",
    "    # max_depths = [i for i in range(1, 21)]\n",
    "    # Thus far, max depths = 20 gives best results.\n",
    "    \n",
    "    mids = [0.5, 1, 2, 5]\n",
    "    \n",
    "    results_fold = []\n",
    "    \n",
    "    for el in mids:\n",
    "    \n",
    "        # Instantiate the Decision Tree Classifier.\n",
    "        model = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split = 500)\n",
    "        model.fit(train_x, train_y)\n",
    "        \n",
    "        # Obtain predictions for the test set.\n",
    "        predictions = model.predict(test_x)\n",
    "        \n",
    "        # Calls persons based on predications. Note the number of success and calls.\n",
    "        total_s = 0\n",
    "        total_c = 0\n",
    "        t_s = [0]\n",
    "        t_c = [0]\n",
    "        \n",
    "#         for loc, pred in enumerate(predictions):\n",
    "#             real = test_df.iloc[loc]\n",
    "#             if pred > real['campaign']:\n",
    "#                 total_c += int(pred)\n",
    "#             else:\n",
    "#                 if real['y'] == 1:\n",
    "#                     total_s += 1\n",
    "#                 total_c += int(pred)\n",
    "#             t_s.append(total_s)\n",
    "#             t_c.append(total_c)\n",
    "        \n",
    "#         results_fold.append(metrics.auc(t_c, t_s))\n",
    "        \n",
    "        acc_score = accuracy_score(test_y, predictions)*100\n",
    "        print(\"Accuracy is: \", acc_score)\n",
    "        \n",
    "    print(results_fold)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: \n",
      "{'criterion': 'entropy', 'max_depth': 24, 'min_impurity_decrease': 5e-05}\n",
      "6567663.6\n"
     ]
    }
   ],
   "source": [
    "def my_custom_score_func(y_test, y_pred):\n",
    "    total_s = 0\n",
    "    total_c = 0\n",
    "    successes = []\n",
    "    calls = []\n",
    "    loc = 0\n",
    "    for df_ref in y_test.index:\n",
    "        actual_value = mkt_df_filtered.loc[df_ref]\n",
    "        if y_pred[loc] <= y_test.iloc[loc]:\n",
    "            if actual_value['y'] == 1:\n",
    "                total_s += 1\n",
    "        total_c += y_pred[loc]\n",
    "        successes.append(total_s)\n",
    "        calls.append(total_c)\n",
    "        loc += 1\n",
    "    score = metrics.auc(calls, successes)\n",
    "    return score\n",
    "\n",
    "custom_score = make_scorer(my_custom_score_func, greater_is_better=True)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt_opt = GridSearchCV(model,\n",
    "                   scoring=custom_score,\n",
    "                   cv=5,\n",
    "                   param_grid={\n",
    "                               \"criterion\": ['gini', 'entropy'],\n",
    "                               \"max_depth\": [i for i in range(1, 25)],\n",
    "                               \"min_impurity_decrease\": [0.00005,0.0001,0.0002,0.0005,0.001,0.0015,0.002,0.005,0.01]\n",
    "                              }\n",
    "    )\n",
    "\n",
    "dt_opt.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters: \")\n",
    "print(dt_opt.best_params_)\n",
    "print(dt_opt.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters were: \n",
    "{'criterion': 'entropy', 'max_depth': 24, 'min_impurity_decrease': 5e-05}\n",
    "with area being -> 6567663.6\n",
    "\n",
    "N.B. This was when we utilized the full range of calls for the output variable .... 1-32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best age groupings! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score function in this case would be essentially the result of the Greedy Approach.\n",
    "def my_custom_score_func(y_test, y_pred):\n",
    "    total_s = 0\n",
    "    total_c = 0\n",
    "    successes = []\n",
    "    calls = []\n",
    "    loc = 0\n",
    "    for df_ref in y_test.index:\n",
    "        actual_value = mkt_df_filtered.loc[df_ref]\n",
    "        if y_pred[loc] <= y_test.iloc[loc]:\n",
    "            if actual_value['y'] == 1:\n",
    "                total_s += 1\n",
    "        total_c += y_pred[loc]\n",
    "        successes.append(total_s)\n",
    "        calls.append(total_c)\n",
    "        loc += 1\n",
    "    score = metrics.auc(calls, successes)\n",
    "    return score\n",
    "\n",
    "custom_score = make_scorer(my_custom_score_func, greater_is_better=True)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt_opt = GridSearchCV(model,\n",
    "                   scoring=custom_score,\n",
    "                   cv=5,\n",
    "                   param_grid={\n",
    "                               \"criterion\": ['gini', 'entropy'],\n",
    "                               \"max_depth\": [i for i in range(1,10)]\n",
    "                               \"min_impurity_decrease\": [0.00005,0.0001,0.0002,0.0005,0.001,0.0015,0.002,0.005,0.01]\n",
    "                              }\n",
    "    )\n",
    "\n",
    "dt_opt.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters: \")\n",
    "print(dt_opt.best_params_)\n",
    "print(dt_opt.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
