{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math, itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from operator import itemgetter\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def load_file(data_file_path):\n",
    "    data_df = pd.read_csv(data_file_path, delimiter=\";\")\n",
    "    return data_df\n",
    "  \n",
    "    \n",
    "def plot_graph_new(results, max_calls, list_passed, title):\n",
    "    x_pts = [i+1 for i in range(0, max_calls)]\n",
    "    if list_passed:\n",
    "        y_pts = results\n",
    "    else:    \n",
    "        y_pts = [results[i]['expected'] for i in range(0, max_calls)]\n",
    "    plt.title(title)\n",
    "    plt.plot(x_pts, y_pts)\n",
    "    plt.axvline(x=0, color =\"black\")\n",
    "    plt.axhline(y=0, color =\"black\")\n",
    "    plt.xticks(np.arange(1, max_calls+1, 1))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# def plot_graph_both_axes(ratios, no_calls):\n",
    "    \n",
    "\n",
    "def div(a,b):\n",
    "    if int(b) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return a/b\n",
    "    \n",
    "\n",
    "# Used for creating all possible combinations of the features.\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = iterable\n",
    "    return itertools.chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "\n",
    "def convert(list): \n",
    "    return tuple(list) \n",
    "\n",
    "\n",
    "def construct_dict(feature_comb):\n",
    "    new_dict = {}\n",
    "    new_dict['education'] = convert(feature_comb[0])\n",
    "    new_dict['job'] = convert(feature_comb[2])\n",
    "    new_dict['marital'] = convert(feature_comb[1])\n",
    "    new_dict['default'] = convert(feature_comb[3])\n",
    "    new_dict['loan'] = convert(feature_comb[4])\n",
    "    new_dict['housing'] = convert(feature_comb[5])\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "# This was the old metric (reward per call rate).\n",
    "# def compute_expected_reward_feature_set_new(fs_df, no_calls_considered):\n",
    "#     expected_values_calls = []\n",
    "#     len_df = len(fs_df)\n",
    "#     for i in range(1, no_calls_considered + 1):\n",
    "#         expected_values_calls.append({'neg_value':0.0, 'pos_value':0.0, 'count':0, 'expected':0.0})\n",
    "#         for index, row in fs_df.iterrows():\n",
    "#             no_calls = row['campaign']\n",
    "#             if no_calls <= i:\n",
    "#                 if row['y'] == \"yes\":\n",
    "#                     expected_values_calls[i-1]['pos_value'] += ((no_calls_considered+1) - no_calls)\n",
    "#                 else:\n",
    "#                     expected_values_calls[i-1]['neg_value'] += (-no_calls)\n",
    "#             else:\n",
    "#                 expected_values_calls[i-1]['neg_value'] += (-i)\n",
    "#             expected_values_calls[i-1]['count'] += 1\n",
    "#     for loc, item in enumerate(expected_values_calls):\n",
    "#         expected_values_calls[loc]['expected'] = (expected_values_calls[loc]['pos_value'] + expected_values_calls[loc]['neg_value'])/len_df\n",
    "#     return expected_values_calls\n",
    "\n",
    "\n",
    "# This is the new metric (success per call rate).\n",
    "def compute_expected_succ_per_call_rate_feature_set(fs_df, no_calls_considered):\n",
    "    expected_values_call_nums = []\n",
    "    for i in range(1, no_calls_considered + 1):\n",
    "        expected_values_call_nums.append({'succ':0, 'total_calls':0, 'expected':0.0})\n",
    "        for index, row in fs_df.iterrows():\n",
    "            no_calls = row['campaign']\n",
    "            if no_calls <= i:\n",
    "                if row['y'] == \"yes\":\n",
    "                    expected_values_call_nums[i-1]['succ'] += 1\n",
    "                    # WHAT SHIT ... (Fixed)\n",
    "                expected_values_call_nums[i-1]['total_calls'] += no_calls\n",
    "            else:\n",
    "                expected_values_call_nums[i-1]['total_calls'] += i\n",
    "    for loc, item in enumerate(expected_values_call_nums):\n",
    "        expected_values_call_nums[loc]['expected'] = div(item['succ'], item['total_calls'])\n",
    "    return expected_values_call_nums\n",
    "\n",
    "\n",
    "def compute_optimal_call_no(results):\n",
    "    max_loc = max(range(len(results)), key=lambda index: results[index]['expected'])\n",
    "#     if results[max_loc]['expected'] <= 0.25:\n",
    "#         return -1\n",
    "#     else:\n",
    "    return max_loc\n",
    "\n",
    "\n",
    "# Given a dictionary of what attributes comprise a feature set, we can get all rows corresponding to this feature set.\n",
    "def extract_rows_feature_set(fs_df, feature_labels = {'education':['tertiary', 'unknown'], \n",
    "                                                      'job':['management', 'technician', 'blue-collar'], \n",
    "                                                      'marital':['single'], 'default':['no'], \n",
    "                                                      'housing':['no'], 'loan':['no']}):\n",
    "    for key in feature_labels:\n",
    "        feature_labels_query_str = ''\n",
    "        arr = feature_labels[key]\n",
    "        for label in arr:\n",
    "            feature_labels_query_str += (key + ' == \"'+ label + '\" | ')\n",
    "        feature_labels_query_str = feature_labels_query_str[:-3]\n",
    "        fs_df = fs_df.query(feature_labels_query_str)\n",
    "    return fs_df\n",
    "\n",
    "\n",
    "def find_matching_attribute_comb(row_value, all_combs):\n",
    "    query = None\n",
    "    for comb in all_combs:\n",
    "        for item in comb:\n",
    "            if item == row_value:\n",
    "                query = comb\n",
    "    return query\n",
    "\n",
    "\n",
    "def compute_metric(df):\n",
    "    total_calls = 0\n",
    "    total_successes = 0\n",
    "    for loc, row in df.iterrows():\n",
    "        if row['y'] == \"yes\":\n",
    "            total_successes += 1\n",
    "        total_calls += row['campaign']\n",
    "    return div(total_successes, total_calls)\n",
    "\n",
    "def compute_metric_2(df):\n",
    "    total_calls = 0\n",
    "    total_successes = 0\n",
    "    for loc, row in df.iterrows():\n",
    "        if row['y'] == \"yes\":\n",
    "            total_successes += 1\n",
    "        total_calls += min(row['campaign'], )\n",
    "    return div(total_successes, total_calls)\n",
    "\n",
    "\n",
    "def compute_metric_for_each_attribute(all_values, df, attrib):\n",
    "    metric_vals = np.zeros(shape=(len(all_values),1))\n",
    "    for index, value in enumerate(all_values):\n",
    "        v_query = \"{0} == '{1}'\".format(attrib, value)\n",
    "        dataset_query = df.query(v_query)\n",
    "        metric_val = compute_metric(dataset_query)\n",
    "        metric_vals[index] = metric_val\n",
    "#         print(v_query, metric_val, dataset_query.shape)\n",
    "    return metric_vals\n",
    "\n",
    "\n",
    "def compute_metric_for_each_attribute_range(all_values, df, attrib):\n",
    "    metric_vals = np.zeros(shape=(len(all_values),1))\n",
    "    query_strings = []\n",
    "    for index, value in enumerate(all_values):\n",
    "        v_query = \"{0} >= {1} & {2} < {3}\".format(attrib, value[0], attrib, value[1])\n",
    "        dataset_query = df.query(v_query)\n",
    "        metric_val = compute_metric(dataset_query)\n",
    "        metric_vals[index] = metric_val\n",
    "        query_strings.append(v_query)\n",
    "#         print(v_query, metric_val, dataset_query.shape)\n",
    "    return metric_vals, query_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_combinations(sub_attributes, ratios):\n",
    "    num_iter = len(ratios)\n",
    "    sil_scores = []\n",
    "    # Making use of the K-Means algorithm ... number of centroids are from 2 to n-1.\n",
    "    for clust_num in range(2, num_iter):\n",
    "        kmeans = KMeans(n_clusters = clust_num)\n",
    "        kmeans.fit(ratios.reshape(-1,1))\n",
    "        results = kmeans.labels_\n",
    "        sil_scores.append((silhouette_score(ratios.reshape(-1,1), results, metric='euclidean'), results, clust_num))\n",
    "    # We make use of the silhouette score to determine the ideal number of centroids.\n",
    "    sorted_sil_scores = sorted(sil_scores, key=lambda x: x[0], reverse = True)\n",
    "    # We then use this ideal number of centroids to determine which sub attributes should be aggregated.\n",
    "    joined_sub_attributes = []\n",
    "    for i in range(0, sorted_sil_scores[0][2]):\n",
    "        joined_sub_attributes.append([])\n",
    "    join_list = sorted_sil_scores[0][1]\n",
    "    for index, value in enumerate(join_list):\n",
    "        pos = join_list[index]\n",
    "        joined_sub_attributes[pos].append(sub_attributes[index])\n",
    "    return_joined_sub_attributes = []\n",
    "    for arr in joined_sub_attributes:\n",
    "        similar_els_gp = []\n",
    "        for item in arr:\n",
    "            similar_els_gp.append(str(item))\n",
    "        return_joined_sub_attributes.append(similar_els_gp)\n",
    "#     print(return_joined_sub_attributes)\n",
    "    return return_joined_sub_attributes\n",
    "\n",
    "# The following is the format of the way in which this method should be called.\n",
    "# find_combinations(['a', 'b', 'c', 'd'], np.array([1, 4, 7, 90]), \"job\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
