{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math, itertools\n",
    "import statistics\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from operator import itemgetter\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "from ipynb.fs.full.helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44967, 17)\n",
      "CPU times: user 111 ms, sys: 42.6 ms, total: 154 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Code that sets up values to construct all possible feature combinations.\n",
    "\n",
    "# Age query strings.\n",
    "# age_query_strings = ['age < 26','age >= 26 & age <=60','age >60']\n",
    "# age_query_strings = ['age >= 10 & age <= 32', 'age >= 33 & age <= 40', 'age >= 50 & age <= 59', 'age >= 60']\n",
    "age_query_strings = ['age >= 10 & age <= 34', 'age >= 35 & age <= 45', 'age >= 46']\n",
    "\n",
    "# Balance query strings.\n",
    "balance_query_strings = ['balance <= 450',' balance > 450']\n",
    "\n",
    "# Max call number to consider.\n",
    "max_calls = 20\n",
    "\n",
    "# Pull and filter all calls <= 20.\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "\n",
    "print(mkt_df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  384\n",
      "Number of FS with small sample sizes:  29\n",
      "Number of combinations:  384\n",
      "Number of FS with small sample sizes:  26\n",
      "Number of combinations:  384\n",
      "Number of FS with small sample sizes:  0\n",
      "Number of combinations:  384\n",
      "Number of FS with small sample sizes:  0\n",
      "Number of combinations:  384\n",
      "Number of FS with small sample sizes:  27\n",
      "Mean Non-Optimal:  0.0512\n",
      "Mean Optimal:  0.0388\n",
      "Std Dev Non-Optimal:  0.012853015210447703\n",
      "Std Dev Optimal:  0.014042791745233568\n",
      "[0.044, 0.062, 0.04, 0.042, 0.068]\n",
      "[0.03, 0.026, 0.056, 0.052, 0.03]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/GitRepos/BankMarketing/helper_fns.ipynb\u001b[0m in \u001b[0;36mcompute_metric_for_each_attribute\u001b[0;34m(all_values, df, attrib)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m\"    for loc, row in df.iterrows():\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"        if row['y'] == \\\"yes\\\":\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;34m\"            total_successes += 1\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;34m\"        total_calls += min(row['campaign'], )\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;34m\"    return div(total_successes, total_calls)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitRepos/BankMarketing/helper_fns.ipynb\u001b[0m in \u001b[0;36mcompute_metric\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;34m\"    query = None\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;34m\"    for comb in all_combs:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;34m\"        for item in comb:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;34m\"            if item == row_value:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m\"                query = comb\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"convert\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Main code ... orchestrates everything!\n",
    "\n",
    "# Splitting dataframe into data and result dataframes.\n",
    "X = mkt_df_filtered.iloc[:,0:len(mkt_df_filtered.columns)-1]\n",
    "y = mkt_df_filtered.iloc[:,-1]   \n",
    "\n",
    "all_non_optimal_ratios = []\n",
    "all_optimal_ratios = []\n",
    "all_call_limits = [500, 1000, 1500]\n",
    "\n",
    "for call_limit in all_call_limits:\n",
    "    for j in range(1,11):\n",
    "        i = 0\n",
    "        kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            i += 1\n",
    "\n",
    "            train_df = mkt_df_filtered.iloc[train_index]\n",
    "            test_df = mkt_df_filtered.iloc[test_index]\n",
    "\n",
    "            # At this point, we can run computations for the success rate of each sub attribute and join\n",
    "            # the sub-attributes based on the output of k-means.\n",
    "            poss = []\n",
    "\n",
    "            # Education.\n",
    "            all_ed = ['tertiary', 'secondary', 'primary', 'unknown']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_ed, train_df, 'education')\n",
    "            education_cmbs = find_combinations(all_ed, metric_vals)\n",
    "\n",
    "            # Occupation.\n",
    "            all_jobs = ['student', 'retired', 'unemployed', 'admin.', 'management', 'self-employed', 'technician', 'unknown', 'services', 'housemaid', 'blue-collar', 'entrepreneur']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_jobs, train_df, 'job')\n",
    "            job_cmbs = find_combinations(all_jobs, metric_vals)\n",
    "\n",
    "            # Marital.\n",
    "            all_ms = ['married', 'single', 'divorced', 'unknown']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_ms, train_df, 'marital')\n",
    "            marital_cmbs = find_combinations(all_ms, metric_vals)\n",
    "\n",
    "            # Default\n",
    "            all_def = ['no', 'yes', 'unknown']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_def, train_df, 'default')\n",
    "            default_cmbs = find_combinations(all_def, metric_vals)\n",
    "\n",
    "            # Loan\n",
    "            all_ln = ['no', 'yes', 'unknown']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_ln, train_df, 'loan')\n",
    "            loan_cmbs = find_combinations(all_ln, metric_vals)\n",
    "\n",
    "            # Housing\n",
    "            all_hs = ['no', 'yes', 'unknown']\n",
    "            metric_vals = compute_metric_for_each_attribute(all_hs, train_df, 'housing')\n",
    "            housing_cmbs = find_combinations(all_hs, metric_vals)\n",
    "\n",
    "            poss.append(education_cmbs)\n",
    "            poss.append(marital_cmbs)\n",
    "            poss.append(job_cmbs)\n",
    "            poss.append(default_cmbs)\n",
    "            poss.append(loan_cmbs)\n",
    "            poss.append(housing_cmbs)\n",
    "            all_combs = list(itertools.product(*poss))\n",
    "\n",
    "            print(\"Number of combinations: \", len(all_combs)* len(age_query_strings) * len(balance_query_strings))\n",
    "\n",
    "            # We can now go ahead and genreate the feature sets based on what was done previously.\n",
    "\n",
    "            num_iter = 0\n",
    "            combs_to_consider = {}\n",
    "            # Setting up looping structures to generate all possibilities.\n",
    "            # All that has to be done now is to change 'df_train' to 'X_train'.\n",
    "            for age_query in age_query_strings:\n",
    "                df_filtered_final = train_df.query(age_query)\n",
    "                for bal_query in balance_query_strings:\n",
    "                    df_filtered_final = df_filtered_final.query(bal_query)\n",
    "                    for comb in all_combs:\n",
    "        #                 print(\"In first comb:\")\n",
    "        #                 print(comb)\n",
    "                        dict_final_query = construct_dict(comb)\n",
    "        #                 print(dict_final_query)\n",
    "                        num_iter += 1\n",
    "                        extracted_df = extract_rows_feature_set(df_filtered_final, dict_final_query)\n",
    "        #                 succ_call_no = [0 for i in range(0,21)]\n",
    "        #                 freq_call_no = [0 for i in range(0,21)]\n",
    "        #                 for loc, row in extracted_df.iterrows():\n",
    "        #                     call_no_loc = row['campaign']\n",
    "        #                     if row['y'] == 'yes':\n",
    "        #                         succ_call_no[call_no_loc] += 1\n",
    "        #                     freq_call_no[call_no_loc] += 1\n",
    "        #                 print(\"Freqs:\")\n",
    "        #                 print(freq_call_no)\n",
    "        #                 print(\"Succs:\")\n",
    "        #                 print(succ_call_no)\n",
    "                        key = (dict_final_query['education'], dict_final_query['job'], dict_final_query['marital'], dict_final_query['default'], dict_final_query['loan'], dict_final_query['housing'], bal_query, age_query)\n",
    "                        n_rows = extracted_df.shape[0]\n",
    "                        if n_rows !=0:\n",
    "        #                     num_non_zero_combs += 1\n",
    "                            results = compute_expected_succ_per_call_rate_feature_set(extracted_df, max_calls)\n",
    "                            max_loc = compute_optimal_call_no(results)\n",
    "                            rate = results[max_loc]['expected']\n",
    "                            # In this new case max_loc never goes below zero!\n",
    "                            if max_loc != 0:\n",
    "                                combs_to_consider[key] = {'age':age_query, 'bal':bal_query, 'comb':comb, 'consider':True, 'max_loc':max_loc, 'rate':results[max_loc]['expected'], 'n_rows':n_rows}\n",
    "        #                     print(age_query)\n",
    "        #                     print(bal_query)\n",
    "        #                     print(comb)\n",
    "        #                     print(dict_final_query)\n",
    "        #                     print(\"Max Loc is: \", max_loc+1)\n",
    "        #                     plot_graph_new(results, max_calls, False, \"Expected Ratio per Call\")\n",
    "        #                     print(\"This ... \\n\\n\")\n",
    "        #  When we are finished creating the feature combinations .... we can now use the hold out set for validation of the model!\n",
    "#             print(\"Iteration: \", i)\n",
    "            # Baseline Metrics\n",
    "            num_succ = 0\n",
    "            num_calls = 0\n",
    "            # Optimal Method Metrics\n",
    "            num_succ_optimal = 0\n",
    "            num_calls_optimal = 0\n",
    "            num_bad_cons = 0\n",
    "            num_good_cons = 0\n",
    "\n",
    "            num_fc_small_sample_size = 0\n",
    "\n",
    "            all_possible_calls = []\n",
    "\n",
    "            for loc, row in test_df.iterrows():\n",
    "                # For optimal method.\n",
    "                # We have the exact values for each of the following:\n",
    "                jb_query = convert(find_matching_attribute_comb(str(row['job']), job_cmbs))\n",
    "                mt_query = convert(find_matching_attribute_comb(str(row['marital']), marital_cmbs))\n",
    "                ec_query = convert(find_matching_attribute_comb(str(row['education']), education_cmbs))\n",
    "                house_query = convert(find_matching_attribute_comb(str(row['housing']), housing_cmbs))\n",
    "                loan_query = convert(find_matching_attribute_comb(str(row['loan']), loan_cmbs))\n",
    "                def_query = convert(find_matching_attribute_comb(str(row['default']), default_cmbs))\n",
    "                ##########################\n",
    "                no_calls = row['campaign']\n",
    "                # The balance and age are within ranges so we need to find the matching query.\n",
    "                ##########################\n",
    "                balance = row['balance']\n",
    "                bal_query = None\n",
    "                age = row['age']\n",
    "                age_query = None\n",
    "                for age_q in age_query_strings:\n",
    "                    if eval(age_q):\n",
    "                        age_query = age_q\n",
    "                for bal_q in balance_query_strings:\n",
    "                    if eval(bal_q):\n",
    "                        bal_query = bal_q\n",
    "                key_to_find = (ec_query, jb_query, mt_query, def_query, loan_query, house_query, bal_query, age_query)\n",
    "                if key_to_find in combs_to_consider.keys():\n",
    "                    fs = combs_to_consider[key_to_find]\n",
    "                    # Adding the rate, feature set, the outcome and the number of calls made to a new list .. which will be sorted afterwards.\n",
    "                    if fs['n_rows'] >= 20:\n",
    "                        all_possible_calls.append((fs['rate'], fs, row['y'], row['campaign']))\n",
    "                    else:\n",
    "                        num_fc_small_sample_size += 1\n",
    "\n",
    "            # Actual Testing ..\n",
    "\n",
    "            total_possible_calls = call_limit\n",
    "\n",
    "            all_possible_calls_sorted = sorted(all_possible_calls, key = lambda tup: tup[0], reverse = True)\n",
    "            subset_df = test_df.sample(n = total_possible_calls)\n",
    "\n",
    "            # Baseline \n",
    "            for loc, row in subset_df.iterrows():\n",
    "                if num_calls + row['campaign'] <= total_possible_calls:\n",
    "                    num_calls += row['campaign']\n",
    "                    if row['y'] == \"yes\":\n",
    "                        num_succ += 1\n",
    "            ratio_baseline = div(num_succ, num_calls)\n",
    "            all_non_optimal_ratios.append(ratio_baseline)\n",
    "#             print(\"Ratio for baseline: \", ratio_baseline)\n",
    "            # Optimal\n",
    "            for item in all_possible_calls_sorted:\n",
    "                if item[3] + num_calls_optimal <= total_possible_calls:\n",
    "                    num_calls_optimal += item[3]\n",
    "                    if item[2] == \"yes\":\n",
    "                        num_succ_optimal += 1\n",
    "            ratio_optimal = div(num_succ_optimal, num_calls_optimal)\n",
    "            all_optimal_ratios.append(ratio_optimal)\n",
    "#             print(\"Ratio for optimal: \", ratio_optimal)  \n",
    "            print(\"Number of FS with small sample sizes: \", num_fc_small_sample_size)\n",
    "#             print(\"\\n\")\n",
    "    mean_non_optimal = statistics.mean(all_non_optimal_ratios)\n",
    "    mean_optimal = statistics.mean(all_optimal_ratios)\n",
    "    std_dev_non_optimal = statistics.stdev(all_non_optimal_ratios)\n",
    "    std_dev_optimal = statistics.stdev(all_optimal_ratios)\n",
    "    print(\"Mean Non-Optimal: \", mean_non_optimal)\n",
    "    print(\"Mean Optimal: \", mean_optimal)\n",
    "    print(\"Std Dev Non-Optimal: \", std_dev_non_optimal)\n",
    "    print(\"Std Dev Optimal: \", std_dev_optimal)\n",
    "    print(all_non_optimal_ratios)\n",
    "    print(all_optimal_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 45\n",
    "for age_q in age_query_strings:\n",
    "    if eval(age_q):\n",
    "        print(\"Yes!\")\n",
    "        print(age_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age and balance computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1326, 17)\n",
      "age < 26 0.11134307585247043\n",
      "(42453, 17)\n",
      "age >= 26 & age <=60 0.03950606355669647\n",
      "(1188, 17)\n",
      "age >60 0.2084717607973422\n"
     ]
    }
   ],
   "source": [
    "# Age.\n",
    "# all_age_query_strings = ['age >= 10 & age <= 32', 'age >= 33 & age <= 40', 'age >= 50 & age <= 59', 'age >= 60']\n",
    "# all_age_query_strings = ['age >= 10 & age <= 34', 'age >= 35 & age <= 45', 'age >= 46']\n",
    "all_age_query_strings = ['age < 26','age >= 26 & age <=60','age >60']\n",
    "for age_query in all_age_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(age_query)\n",
    "    print(df_filtered_final.shape)\n",
    "    print(age_query, compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 17)\n",
      "age >= 10 & age <= 19 47 0.14634146341463414\n",
      "(5189, 17)\n",
      "age >= 20 & age <= 29 5189 0.07631601041054488\n",
      "(17989, 17)\n",
      "age >= 30 & age <= 39 17989 0.040097307272879794\n",
      "(11584, 17)\n",
      "age >= 40 & age <= 49 11584 0.03357253501090633\n",
      "(8375, 17)\n",
      "age >= 50 & age <= 59 8375 0.03437390389337075\n",
      "(1229, 17)\n",
      "age >= 60 & age <= 69 1229 0.12427647259107934\n",
      "(424, 17)\n",
      "age >= 70 & age <= 79 424 0.20594965675057209\n",
      "(130, 17)\n",
      "age >= 80 & age <= 100 130 0.1950354609929078\n"
     ]
    }
   ],
   "source": [
    "# Age.\n",
    "all_age_query_strings = ['age >= 10 & age <= 19', 'age >= 20 & age <= 29', 'age >= 30 & age <= 39', 'age >= 40 & age <= 49', 'age >= 50 & age <= 59','age >= 60 & age <= 69', 'age >= 70 & age <= 79', 'age >= 80 & age <= 100']\n",
    "# all_age_query_strings = ['age >= 10 & age <= 100']\n",
    "for age_query in all_age_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(age_query)\n",
    "    print(df_filtered_final.shape)\n",
    "    print(age_query, len(df_filtered_final), compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "all_age_query_tuples = [(10, 20), (20, 30), (30, 40), (50, 60), (60, 70), (70, 80), (80, 90), (90, 100)]\n",
    "ratios, all_age_query_strings = compute_metric_for_each_attribute_range(all_age_query_tuples, train_df, 'age')\n",
    "find_combinations(all_age_query_strings, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Balance\n",
    "all_bal_query_strings = ['balance >= -100000 & balance <= -1', 'balance >= 0 & balance < 250', 'balance >= 250 & balance < 500','balance >= 500 & balance < 750', 'balance >= 750 & balance < 1000', 'balance >= 1000 & balance < 2000', 'balance >= 2000 & balance < 3000', 'balance >= 3000 & balance < 4000','balance >= 4000 & balance < 5000', 'balance >= 5000 & balance < 6000', 'balance >= 6000 & balance < 7000', 'balance >= 7000 & balance < 8000', 'balance >= 8000 & balance < 9000', 'balance >= 9000 & balance < 10000','balance >= 10000 & balance < 11000', 'balance >= 11000 & balance < 12000', 'balance >= 12000 & balance < 13000', 'balance >= 13000 & balance < 14000', 'balance >= 14000 & balance < 15000', 'balance >= 15000 & balance < 16000', 'balance >= 16000 & balance < 17000','balance >= 17000 & balance < 18000', 'balance >= 18000 & balance < 19000', 'balance >= 19000 & balance < 19000', 'balance >= 20000']\n",
    "for bal_query in all_bal_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(bal_query)\n",
    "    print(bal_query, len(df_filtered_final), compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance\n",
    "all_bal_query_tuples = [(-10000, 0), (0, 250), (250, 500), (500, 750), (750,1000), (1000, 2000), (2000, 3000), (3000, 4000), (4000, 5000), (5000, 6000), (6000, 7000), (8000, 100000)]\n",
    "ratios, all_bal_query_strings = compute_metric_for_each_attribute_range(all_bal_query_tuples, train_df, 'balance')\n",
    "find_combinations(all_bal_query_strings, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining where to stop regarding the number of calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to determine the maximum number of calls we should stop at!\n",
    "all_ratios_calls = []\n",
    "for i in range(1,57):\n",
    "    query_str = 'campaign == ' + str(i)\n",
    "    call_query_data = mkt_df_filtered.query(query_str)\n",
    "    succ = 0\n",
    "    calls = 0\n",
    "    for lc, rw in call_query_data.iterrows():\n",
    "        if rw['y'] == \"yes\":\n",
    "            succ += 1\n",
    "        calls += rw['campaign']\n",
    "    all_ratios_calls.append(div(succ, calls))\n",
    "for index, value in enumerate(all_ratios_calls):\n",
    "    print(index+1, value)\n",
    "plot_graph_new(all_ratios_calls, 56, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the success rate by optimizing the maximum calls made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calls_considered = 20\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls_considered)]\n",
    "\n",
    "result_ratios = [0.0 for i in range (1,max_calls_considered+1)]\n",
    "\n",
    "for i in range(1, max_calls_considered+1):\n",
    "    total_calls = 0\n",
    "    total_succ = 0\n",
    "    #query_str = \"campaign <= {0}\".format(i)\n",
    "    #print(query_str)\n",
    "    #df_filtered_campaign = mkt_df_filtered.query(query_str)\n",
    "    for loc, row in mkt_df_filtered.iterrows():\n",
    "        if row['y']  == \"yes\" and row['campaign'] <= i:\n",
    "            total_succ += 1\n",
    "        total_calls += min(i, row['campaign'])\n",
    "    result_ratios[i-1] = div(total_succ , total_calls)\n",
    "    print(i, result_ratios[i-1], total_succ, total_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_new(result_ratios, 20, True, \"Ratio Per Call #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "mkt_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered['poutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered_successes = mkt_df_filtered.query(\"poutcome == 'success'\")\n",
    "print(mkt_df_filtered_successes.shape)\n",
    "mkt_df_filtered_successes['previous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered_successes['poutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mkt_df_filtered_successes['campaign'].value_counts(normalize = False)\n",
    "print(res)\n",
    "print(res.values)\n",
    "num_succ = [2561, 1401 , 618, 317, 139, 92, 47, 32, 21, 14, 16, 4, 6, 4, 4, 2, 6, 0, 0 ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_new(num_succ, 20, True, \"Frequency of Contacts Made per Call #\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To conduct further analysis we need to determine:\n",
    "    - The probability that someone was successful for this campaign given that \n",
    "    they were either successful or not for the last campaign.\n",
    "    - Correlate the time spent on the last call and the success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mkt_df_filtered.query(\"y == 'yes'\").shape[0]\n",
    "b = mkt_df_filtered.query(\"poutcome == 'success'\").shape[0]\n",
    "anb = mkt_df_filtered.query(\"y == 'yes' and poutcome == 'success'\").shape[0]\n",
    "print(anb/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4920, 60):\n",
    "    res = mkt_df_filtered.query(\"duration >= {0} and duration <= {1}\".format(str(i-60), str(i)))\n",
    "    print(i, res.shape[0], res.query(\"y == 'yes'\").shape[0])\n",
    "# a = mkt_df_filtered.query(\"duration >= 0 and duration <= 180\").shape[0]\n",
    "# b = mkt_df_filtered.query(\"y == 'yes'\").shape[0]\n",
    "# anb = mkt_df_filtered.query(\"y == 'yes' and duration >= 0 and duration <= 1000\").shape[0]\n",
    "# print(anb/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int(mkt_df_filtered['duration'].max()/60)+1\n",
    "int(mkt_df_filtered['duration'].max()/60) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mkt_df_filtered.query(\"y == 'yes' and contact == 'cellular'\").shape[0]\n",
    "b = mkt_df_filtered.query(\"y == 'yes' and contact == 'telephone'\").shape[0]\n",
    "c = mkt_df_filtered.query('y == \"yes\"').shape[0]\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
