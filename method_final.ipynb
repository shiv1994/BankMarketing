{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math, itertools\n",
    "import statistics\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from operator import itemgetter\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import Counter\n",
    "from ipynb.fs.full.helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44967, 17)\n"
     ]
    }
   ],
   "source": [
    "# Code that sets up values to construct all possible feature combinations.\n",
    "\n",
    "# Age query strings.\n",
    "# age_query_strings = ['age < 26','age >= 26 & age <=60','age >60']\n",
    "age_query_strings = ['age >= 10 & age <= 32', 'age >= 33 & age <= 40', 'age >= 50 & age <= 59', 'age >= 60']\n",
    "\n",
    "# Balance query strings.\n",
    "balance_query_strings = ['balance <= 450',' balance > 450']\n",
    "\n",
    "# Max call number to consider.\n",
    "max_calls = 20\n",
    "\n",
    "# Pull and filter all calls <= 20.\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "\n",
    "print(mkt_df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  512\n",
      "Iteration:  1\n",
      "Ratio for baseline:  0.042\n",
      "Ratio for optimal:  0.05\n",
      "Number of FS with small sample sizes:  0\n",
      "\n",
      "\n",
      "Number of combinations:  512\n",
      "Iteration:  2\n",
      "Ratio for baseline:  0.028\n",
      "Ratio for optimal:  0.044\n",
      "Number of FS with small sample sizes:  0\n",
      "\n",
      "\n",
      "Number of combinations:  512\n",
      "Iteration:  3\n",
      "Ratio for baseline:  0.05\n",
      "Ratio for optimal:  0.08179419525065963\n",
      "Number of FS with small sample sizes:  0\n",
      "\n",
      "\n",
      "Number of combinations:  512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-83d3a1042653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#                 print(dict_final_query)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mnum_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mextracted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_rows_feature_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filtered_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_final_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;31m#                 succ_call_no = [0 for i in range(0,21)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m#                 freq_call_no = [0 for i in range(0,21)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/BankMarketing/helper_fns.ipynb\u001b[0m in \u001b[0;36mextract_rows_feature_set\u001b[0;34m(fs_df, feature_labels)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;34m\"# Given a dictionary of what attributes comprise a feature set, we can get all rows corresponding to this feature set.\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;34m\"def extract_rows_feature_set(fs_df, feature_labels = {'education':['tertiary', 'unknown'], \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;34m\"                                                      'job':['management', 'technician', 'blue-collar'], \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m\"                                                      'marital':['single'], 'default':['no'], \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3197\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3199\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3201\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3313\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3314\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    320\u001b[0m         )\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mparsed_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# construct the engine and evaluate the parsed expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, expr, engine, parser, env, truediv, level)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"truediv\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parsers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;34m\"\"\"Parse an expression\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_missing_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m_preparse\u001b[0;34m(source, f)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \"\"\"\n\u001b[1;32m    205\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f must be callable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36muntokenize\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \"\"\"\n\u001b[1;32m    332\u001b[0m     \u001b[0mut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUntokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36muntokenize\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mindents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mstartline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \"\"\"\n\u001b[1;32m    205\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f must be callable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muntokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mtokenize_string\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[1;32m     52\u001b[0m     \u001b[0mline_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtoken_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Loop over all tokens till a backtick (`) is found.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36mgenerate_tokens\u001b[0;34m(readline)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;31m# An undocumented, backwards compatible, API for all the places in the standard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;31m# library that expect to be able to use tokenize with strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main code ... orchestrates everything!\n",
    "\n",
    "# Splitting dataframe into data and result dataframes.\n",
    "X = mkt_df_filtered.iloc[:,0:len(mkt_df_filtered.columns)-1]\n",
    "y = mkt_df_filtered.iloc[:,-1]   \n",
    "\n",
    "all_non_optimal_ratios = []\n",
    "all_optimal_ratios = []\n",
    "\n",
    "i = 0\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    i += 1\n",
    "    \n",
    "    train_df = mkt_df_filtered.iloc[train_index]\n",
    "    test_df = mkt_df_filtered.iloc[test_index]\n",
    "    \n",
    "    # At this point, we can run computations for the success rate of each sub attribute and join\n",
    "    # the sub-attributes based on the output of k-means.\n",
    "    poss = []\n",
    "    \n",
    "    # Education.\n",
    "    all_ed = ['tertiary', 'secondary', 'primary', 'unknown']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_ed, train_df, 'education')\n",
    "    education_cmbs = find_combinations(all_ed, metric_vals)\n",
    "    \n",
    "    # Occupation.\n",
    "    all_jobs = ['student', 'retired', 'unemployed', 'admin.', 'management', 'self-employed', 'technician', 'unknown', 'services', 'housemaid', 'blue-collar', 'entrepreneur']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_jobs, train_df, 'job')\n",
    "    job_cmbs = find_combinations(all_jobs, metric_vals)\n",
    "    \n",
    "    # Marital.\n",
    "    all_ms = ['married', 'single', 'divorced', 'unknown']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_ms, train_df, 'marital')\n",
    "    marital_cmbs = find_combinations(all_ms, metric_vals)\n",
    "    \n",
    "    # Default\n",
    "    all_def = ['no', 'yes', 'unknown']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_def, train_df, 'default')\n",
    "    default_cmbs = find_combinations(all_def, metric_vals)\n",
    "    \n",
    "    # Loan\n",
    "    all_ln = ['no', 'yes', 'unknown']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_ln, train_df, 'loan')\n",
    "    loan_cmbs = find_combinations(all_ln, metric_vals)\n",
    "    \n",
    "    # Housing\n",
    "    all_hs = ['no', 'yes', 'unknown']\n",
    "    metric_vals = compute_metric_for_each_attribute(all_hs, train_df, 'housing')\n",
    "    housing_cmbs = find_combinations(all_hs, metric_vals)\n",
    "    \n",
    "    poss.append(education_cmbs)\n",
    "    poss.append(marital_cmbs)\n",
    "    poss.append(job_cmbs)\n",
    "    poss.append(default_cmbs)\n",
    "    poss.append(loan_cmbs)\n",
    "    poss.append(housing_cmbs)\n",
    "    all_combs = list(itertools.product(*poss))\n",
    "    \n",
    "    print(\"Number of combinations: \", len(all_combs)* len(age_query_strings) * len(balance_query_strings))\n",
    "    \n",
    "    # We can now go ahead and genreate the feature sets based on what was done previously.\n",
    "    \n",
    "    num_iter = 0\n",
    "    combs_to_consider = {}\n",
    "    # Setting up looping structures to generate all possibilities.\n",
    "    # All that has to be done now is to change 'df_train' to 'X_train'.\n",
    "    for age_query in age_query_strings:\n",
    "        df_filtered_final = train_df.query(age_query)\n",
    "        for bal_query in balance_query_strings:\n",
    "            df_filtered_final = df_filtered_final.query(bal_query)\n",
    "            for comb in all_combs:\n",
    "#                 print(\"In first comb:\")\n",
    "#                 print(comb)\n",
    "                dict_final_query = construct_dict(comb)\n",
    "#                 print(dict_final_query)\n",
    "                num_iter += 1\n",
    "                extracted_df = extract_rows_feature_set(df_filtered_final, dict_final_query)\n",
    "#                 succ_call_no = [0 for i in range(0,21)]\n",
    "#                 freq_call_no = [0 for i in range(0,21)]\n",
    "#                 for loc, row in extracted_df.iterrows():\n",
    "#                     call_no_loc = row['campaign']\n",
    "#                     if row['y'] == 'yes':\n",
    "#                         succ_call_no[call_no_loc] += 1\n",
    "#                     freq_call_no[call_no_loc] += 1\n",
    "#                 print(\"Freqs:\")\n",
    "#                 print(freq_call_no)\n",
    "#                 print(\"Succs:\")\n",
    "#                 print(succ_call_no)\n",
    "                key = (dict_final_query['education'], dict_final_query['job'], dict_final_query['marital'], dict_final_query['default'], dict_final_query['loan'], dict_final_query['housing'], bal_query, age_query)\n",
    "                n_rows = extracted_df.shape[0]\n",
    "                if n_rows !=0:\n",
    "#                     num_non_zero_combs += 1\n",
    "                    results = compute_expected_succ_per_call_rate_feature_set(extracted_df, max_calls)\n",
    "                    max_loc = compute_optimal_call_no(results)\n",
    "                    rate = results[max_loc]['expected']\n",
    "                    # In this new case max_loc never goes below zero!\n",
    "                    if max_loc != 0:\n",
    "                        combs_to_consider[key] = {'age':age_query, 'bal':bal_query, 'comb':comb, 'consider':True, 'max_loc':max_loc, 'rate':results[max_loc]['expected'], 'n_rows':n_rows}\n",
    "#                     print(age_query)\n",
    "#                     print(bal_query)\n",
    "#                     print(comb)\n",
    "#                     print(dict_final_query)\n",
    "#                     print(\"Max Loc is: \", max_loc+1)\n",
    "#                     plot_graph_new(results, max_calls, False, \"Expected Ratio per Call\")\n",
    "#                     print(\"This ... \\n\\n\")\n",
    "#  When we are finished creating the feature combinations .... we can now use the hold out set for validation of the model!\n",
    "    print(\"Iteration: \", i)\n",
    "    # Baseline Metrics\n",
    "    num_succ = 0\n",
    "    num_calls = 0\n",
    "    # Optimal Method Metrics\n",
    "    num_succ_optimal = 0\n",
    "    num_calls_optimal = 0\n",
    "    num_bad_cons = 0\n",
    "    num_good_cons = 0\n",
    "    \n",
    "    num_fc_small_sample_size = 0\n",
    "    \n",
    "    all_possible_calls = []\n",
    "    \n",
    "    for loc, row in test_df.iterrows():\n",
    "        # For optimal method.\n",
    "        # We have the exact values for each of the following:\n",
    "        jb_query = convert(find_matching_attribute_comb(str(row['job']), job_cmbs))\n",
    "        mt_query = convert(find_matching_attribute_comb(str(row['marital']), marital_cmbs))\n",
    "        ec_query = convert(find_matching_attribute_comb(str(row['education']), education_cmbs))\n",
    "        house_query = convert(find_matching_attribute_comb(str(row['housing']), housing_cmbs))\n",
    "        loan_query = convert(find_matching_attribute_comb(str(row['loan']), loan_cmbs))\n",
    "        def_query = convert(find_matching_attribute_comb(str(row['default']), default_cmbs))\n",
    "        ##########################\n",
    "        no_calls = row['campaign']\n",
    "        # The balance and age are within ranges so we need to find the matching query.\n",
    "        ##########################\n",
    "        balance = row['balance']\n",
    "        bal_query = None\n",
    "        age = row['age']\n",
    "        age_query = None\n",
    "        for age_q in age_query_strings:\n",
    "            if eval(age_q):\n",
    "                age_query = age_q\n",
    "        for bal_q in balance_query_strings:\n",
    "            if eval(bal_q):\n",
    "                bal_query = bal_q\n",
    "        key_to_find = (ec_query, jb_query, mt_query, def_query, loan_query, house_query, bal_query, age_query)\n",
    "        if key_to_find in combs_to_consider.keys():\n",
    "            fs = combs_to_consider[key_to_find]\n",
    "            # Adding the rate, feature set, the outcome and the number of calls made to a new list .. which will be sorted afterwards.\n",
    "            if fs['n_rows'] >= 20:\n",
    "                all_possible_calls.append((fs['rate'], fs, row['y'], row['campaign']))\n",
    "            else:\n",
    "                num_fc_small_sample_size += 1\n",
    "    \n",
    "    # Actual Testing ..\n",
    "    \n",
    "    total_possible_calls = 500\n",
    "    \n",
    "    all_possible_calls_sorted = sorted(all_possible_calls, key = lambda tup: tup[0], reverse = True)\n",
    "    subset_df = test_df.sample(n = total_possible_calls)\n",
    "    \n",
    "    # Baseline \n",
    "    for loc, row in subset_df.iterrows():\n",
    "        if num_calls + row['campaign'] <= total_possible_calls:\n",
    "            num_calls += row['campaign']\n",
    "            if row['y'] == \"yes\":\n",
    "                num_succ += 1\n",
    "    ratio_baseline = div(num_succ, num_calls)\n",
    "    all_non_optimal_ratios.append(ratio_baseline)\n",
    "    print(\"Ratio for baseline: \", ratio_baseline)\n",
    "    \n",
    "    # Optimal\n",
    "    for item in all_possible_calls_sorted:\n",
    "        if item[3] + num_calls_optimal <= total_possible_calls:\n",
    "            num_calls_optimal += item[3]\n",
    "            if item[2] == \"yes\":\n",
    "                num_succ_optimal += 1\n",
    "    ratio_optimal = div(num_succ_optimal, num_calls_optimal)\n",
    "    all_optimal_ratios.append(ratio_optimal)\n",
    "    print(\"Ratio for optimal: \", ratio_optimal)  \n",
    "    print(\"Number of FS with small sample sizes: \", num_fc_small_sample_size)\n",
    "    print(\"\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Non-Optimal:  0.0464\n",
      "Mean Optimal:  0.06809302325581396\n",
      "[0.044, 0.048, 0.032, 0.048, 0.06]\n",
      "[0.11046511627906977, 0.042, 0.084, 0.03, 0.074]\n"
     ]
    }
   ],
   "source": [
    "mean_non_optimal = statistics.mean(all_non_optimal_ratios)\n",
    "mean_optimal = statistics.mean(all_optimal_ratios)\n",
    "print(\"Mean Non-Optimal: \", mean_non_optimal)\n",
    "print(\"Mean Optimal: \", mean_optimal)\n",
    "print(all_non_optimal_ratios)\n",
    "print(all_optimal_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 45\n",
    "for age_q in age_query_strings:\n",
    "    if eval(age_q):\n",
    "        print(\"Yes!\")\n",
    "        print(age_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age and balance computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age.\n",
    "all_age_query_strings = ['age >= 10 & age <= 32', 'age >= 33 & age <= 40', 'age >= 50 & age <= 59', 'age >= 60']\n",
    "for age_query in all_age_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(age_query)\n",
    "    print(df_filtered_final.shape)\n",
    "    print(age_query, compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age.\n",
    "all_age_query_strings = ['age >= 10 & age <= 19', 'age >= 20 & age <= 29', 'age >= 30 & age <= 39', 'age >= 40 & age <= 49', 'age >= 50 & age <= 59','age >= 60 & age <= 69', 'age >= 70 & age <= 79', 'age >= 80 & age <= 100']\n",
    "all_age_query_strings = ['age >= 10 & age <= 100']\n",
    "for age_query in all_age_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(age_query)\n",
    "    print(df_filtered_final.shape)\n",
    "    print(age_query, len(df_filtered_final), compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "all_age_query_tuples = [(10, 20), (20, 30), (30, 40), (50, 60), (60, 70), (70, 80), (80, 90), (90, 100)]\n",
    "ratios, all_age_query_strings = compute_metric_for_each_attribute_range(all_age_query_tuples, train_df, 'age')\n",
    "find_combinations(all_age_query_strings, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Balance\n",
    "all_bal_query_strings = ['balance >= -100000 & balance <= -1', 'balance >= 0 & balance < 250', 'balance >= 250 & balance < 500','balance >= 500 & balance < 750', 'balance >= 750 & balance < 1000', 'balance >= 1000 & balance < 2000', 'balance >= 2000 & balance < 3000', 'balance >= 3000 & balance < 4000','balance >= 4000 & balance < 5000', 'balance >= 5000 & balance < 6000', 'balance >= 6000 & balance < 7000', 'balance >= 7000 & balance < 8000', 'balance >= 8000 & balance < 9000', 'balance >= 9000 & balance < 10000','balance >= 10000 & balance < 11000', 'balance >= 11000 & balance < 12000', 'balance >= 12000 & balance < 13000', 'balance >= 13000 & balance < 14000', 'balance >= 14000 & balance < 15000', 'balance >= 15000 & balance < 16000', 'balance >= 16000 & balance < 17000','balance >= 17000 & balance < 18000', 'balance >= 18000 & balance < 19000', 'balance >= 19000 & balance < 19000', 'balance >= 20000']\n",
    "for bal_query in all_bal_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(bal_query)\n",
    "    print(bal_query, len(df_filtered_final), compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance\n",
    "all_bal_query_tuples = [(-10000, 0), (0, 250), (250, 500), (500, 750), (750,1000), (1000, 2000), (2000, 3000), (3000, 4000), (4000, 5000), (5000, 6000), (6000, 7000), (8000, 100000)]\n",
    "ratios, all_bal_query_strings = compute_metric_for_each_attribute_range(all_bal_query_tuples, train_df, 'balance')\n",
    "find_combinations(all_bal_query_strings, ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining where to stop regarding the number of calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to determine the maximum number of calls we should stop at!\n",
    "all_ratios_calls = []\n",
    "for i in range(1,57):\n",
    "    query_str = 'campaign == ' + str(i)\n",
    "    call_query_data = mkt_df_filtered.query(query_str)\n",
    "    succ = 0\n",
    "    calls = 0\n",
    "    for lc, rw in call_query_data.iterrows():\n",
    "        if rw['y'] == \"yes\":\n",
    "            succ += 1\n",
    "        calls += rw['campaign']\n",
    "    all_ratios_calls.append(div(succ, calls))\n",
    "for index, value in enumerate(all_ratios_calls):\n",
    "    print(index+1, value)\n",
    "plot_graph_new(all_ratios_calls, 56, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the success rate by optimizing the maximum calls made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_calls_considered = 20\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls_considered)]\n",
    "\n",
    "result_ratios = [0.0 for i in range (1,max_calls_considered+1)]\n",
    "\n",
    "for i in range(1, max_calls_considered+1):\n",
    "    total_calls = 0\n",
    "    total_succ = 0\n",
    "    #query_str = \"campaign <= {0}\".format(i)\n",
    "    #print(query_str)\n",
    "    #df_filtered_campaign = mkt_df_filtered.query(query_str)\n",
    "    for loc, row in mkt_df_filtered.iterrows():\n",
    "        if row['y']  == \"yes\" and row['campaign'] <= i:\n",
    "            total_succ += 1\n",
    "        total_calls += min(i, row['campaign'])\n",
    "    result_ratios[i-1] = div(total_succ , total_calls)\n",
    "    print(i, result_ratios[i-1], total_succ, total_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_new(result_ratios, 20, True, \"Ratio Per Call #\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "mkt_df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered['poutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered_successes = mkt_df_filtered.query(\"poutcome == 'success'\")\n",
    "print(mkt_df_filtered_successes.shape)\n",
    "mkt_df_filtered_successes['previous'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt_df_filtered_successes['poutcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mkt_df_filtered_successes['campaign'].value_counts(normalize = False)\n",
    "print(res)\n",
    "print(res.values)\n",
    "num_succ = [2561, 1401 , 618, 317, 139, 92, 47, 32, 21, 14, 16, 4, 6, 4, 4, 2, 6, 0, 0 ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_new(num_succ, 20, True, \"Frequency of Contacts Made per Call #\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To conduct further analysis we need to determine:\n",
    "    - The probability that someone was successful for this campaign given that \n",
    "    they were either successful or not for the last campaign.\n",
    "    - Correlate the time spent on the last call and the success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mkt_df_filtered.query(\"y == 'yes'\").shape[0]\n",
    "b = mkt_df_filtered.query(\"poutcome == 'success'\").shape[0]\n",
    "anb = mkt_df_filtered.query(\"y == 'yes' and poutcome == 'success'\").shape[0]\n",
    "print(anb/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4920, 60):\n",
    "    res = mkt_df_filtered.query(\"duration >= {0} and duration <= {1}\".format(str(i-60), str(i)))\n",
    "    print(i, res.shape[0], res.query(\"y == 'yes'\").shape[0])\n",
    "# a = mkt_df_filtered.query(\"duration >= 0 and duration <= 180\").shape[0]\n",
    "# b = mkt_df_filtered.query(\"y == 'yes'\").shape[0]\n",
    "# anb = mkt_df_filtered.query(\"y == 'yes' and duration >= 0 and duration <= 1000\").shape[0]\n",
    "# print(anb/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int(mkt_df_filtered['duration'].max()/60)+1\n",
    "int(mkt_df_filtered['duration'].max()/60) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mkt_df_filtered.query(\"y == 'yes' and contact == 'cellular'\").shape[0]\n",
    "b = mkt_df_filtered.query(\"y == 'yes' and contact == 'telephone'\").shape[0]\n",
    "c = mkt_df_filtered.query('y == \"yes\"').shape[0]\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
