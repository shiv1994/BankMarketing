{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math, itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from operator import itemgetter\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "\n",
    "def load_file(data_file_path):\n",
    "    data_df = pd.read_csv(data_file_path, delimiter=\";\")\n",
    "    return data_df\n",
    "  \n",
    "    \n",
    "def plot_graph_new(results, max_calls):\n",
    "    x_pts = [i+1 for i in range(0, max_calls)]\n",
    "    y_pts = [results[i]['expected'] for i in range(0, max_calls)]\n",
    "    plt.title(\"Plot of Expected Success Per Call Rate\")\n",
    "    plt.plot(x_pts, y_pts)\n",
    "    plt.axvline(x=0, color =\"black\")\n",
    "    plt.axhline(y=0, color =\"black\")\n",
    "    plt.xticks(np.arange(1, max_calls+1, 1))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def div(a,b):\n",
    "    if int(b) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return a/b\n",
    "    \n",
    "\n",
    "# Used for creating all possible combinations of the features.\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = iterable\n",
    "    return itertools.chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "\n",
    "def construct_dict(feature_comb):\n",
    "    new_dict = {}\n",
    "    new_dict['education'] = feature_comb[0]\n",
    "    new_dict['job'] = feature_comb[2]\n",
    "    new_dict['marital'] = feature_comb[1]\n",
    "    new_dict['default'] = feature_comb[3]\n",
    "    new_dict['loan'] = feature_comb[4]\n",
    "    new_dict['housing'] = feature_comb[5]\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "# This was the old metric (reward per call rate).\n",
    "# def compute_expected_reward_feature_set_new(fs_df, no_calls_considered):\n",
    "#     expected_values_calls = []\n",
    "#     len_df = len(fs_df)\n",
    "#     for i in range(1, no_calls_considered + 1):\n",
    "#         expected_values_calls.append({'neg_value':0.0, 'pos_value':0.0, 'count':0, 'expected':0.0})\n",
    "#         for index, row in fs_df.iterrows():\n",
    "#             no_calls = row['campaign']\n",
    "#             if no_calls <= i:\n",
    "#                 if row['y'] == \"yes\":\n",
    "#                     expected_values_calls[i-1]['pos_value'] += ((no_calls_considered+1) - no_calls)\n",
    "#                 else:\n",
    "#                     expected_values_calls[i-1]['neg_value'] += (-no_calls)\n",
    "#             else:\n",
    "#                 expected_values_calls[i-1]['neg_value'] += (-i)\n",
    "#             expected_values_calls[i-1]['count'] += 1\n",
    "#     for loc, item in enumerate(expected_values_calls):\n",
    "#         expected_values_calls[loc]['expected'] = (expected_values_calls[loc]['pos_value'] + expected_values_calls[loc]['neg_value'])/len_df\n",
    "#     return expected_values_calls\n",
    "\n",
    "\n",
    "# This is the new metric (success per call rate).\n",
    "def compute_expected_succ_per_call_rate_feature_set(fs_df, no_calls_considered):\n",
    "    expected_values_call_nums = []\n",
    "    for i in range(1, no_calls_considered + 1):\n",
    "        expected_values_call_nums.append({'succ':0, 'total_calls':0, 'expected':0.0})\n",
    "        for index, row in fs_df.iterrows():\n",
    "            no_calls = row['campaign']\n",
    "            if no_calls <= i:\n",
    "                if row['y'] == \"yes\":\n",
    "                    expected_values_call_nums[i-1]['succ'] += 1\n",
    "                    expected_values_call_nums[i-1]['total_calls'] += no_calls\n",
    "            else:\n",
    "                expected_values_call_nums[i-1]['total_calls'] += i\n",
    "    for loc, item in enumerate(expected_values_call_nums):\n",
    "        expected_values_call_nums[loc]['expected'] = div(item['succ'], item['total_calls'])\n",
    "    return expected_values_call_nums\n",
    "\n",
    "\n",
    "def compute_optimal_call_no(results):\n",
    "    max_loc = max(range(len(results)), key=lambda index: results[index]['expected'])\n",
    "    if results[max_loc]['expected'] < 0.0:\n",
    "        return -1\n",
    "    else:\n",
    "        return max_loc\n",
    "\n",
    "\n",
    "# Given a dictionary of what attributes comprise a feature set, we can get all rows corresponding to this feature set.\n",
    "def extract_rows_feature_set(fs_df, feature_labels = {'education':['tertiary', 'unknown'], \n",
    "                                                      'job':['management', 'technician', 'blue-collar'], \n",
    "                                                      'marital':['single'], 'default':['no'], \n",
    "                                                      'housing':['no'], 'loan':['no']}):\n",
    "    for key in feature_labels:\n",
    "        feature_labels_query_str = ''\n",
    "        arr = feature_labels[key]\n",
    "        for label in arr:\n",
    "            feature_labels_query_str += (key + ' == \"'+ label + '\" | ')\n",
    "        feature_labels_query_str = feature_labels_query_str[:-3]\n",
    "        fs_df = fs_df.query(feature_labels_query_str)\n",
    "    return fs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that sets up values to construct all possible feature combinations.\n",
    "\n",
    "poss = []\n",
    "\n",
    "poss.append([['tertiary', 'unknown'],['primary','secondary']])\n",
    "poss.append([['single'],['married'],['divorced']])\n",
    "poss.append([['student','retired','unemployed'],['admin', 'management', 'self-employed'],['technician', 'unknown', 'services'],['housemaid', 'blue-collar', 'entrepreneur']])\n",
    "poss.append([['no'],['yes']])\n",
    "poss.append([['no'],['yes']])\n",
    "poss.append([['no'],['yes']])\n",
    "all_combs = list(itertools.product(*poss))\n",
    "\n",
    "# Age query strings.\n",
    "age_query_strings = ['age < 26','age >= 26 & age <=60','age >60']\n",
    "\n",
    "# Balance query strings.\n",
    "balance_query_strings = ['balance <= 5000',' balance > 5000']\n",
    "\n",
    "# Max call number to consider.\n",
    "# We obtained this by dividing the overall reward we have in the dataset by the number of successes.\n",
    "max_calls = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code for computing info regarding each feature set.\n",
    "\n",
    "# Pull and filter all calls <= 20.\n",
    "current_dir = os.getcwd()\n",
    "mkt_df = load_file(current_dir + '/bank-full.csv')\n",
    "mkt_df_filtered = mkt_df[(mkt_df['campaign']>=1) & (mkt_df['campaign']<=max_calls)]\n",
    "\n",
    "\n",
    "# Splitting into train(80%) and test(20%) sets.\n",
    "X = mkt_df_filtered.iloc[:,0:len(mkt_df_filtered.columns)-1]\n",
    "y = mkt_df_filtered.iloc[:,-1]\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.25, random_state=0)\n",
    "for train_indicies, test_indicies in rs.split(X):\n",
    "    df_train = mkt_df_filtered.iloc[train_indicies]\n",
    "    df_test = mkt_df_filtered.iloc[test_indicies]\n",
    "\n",
    "\n",
    "# Setting up looping structures to generate all possibilities.\n",
    "num_iter = 0\n",
    "num_non_zero_combs = 0\n",
    "\n",
    "combs_to_consider = []\n",
    "\n",
    "for age_query in age_query_strings:\n",
    "    df_filtered_final = df_train.query(age_query)\n",
    "    for bal_query in balance_query_strings:\n",
    "        df_filtered_final = df_filtered_final.query(bal_query)\n",
    "        for comb in all_combs:\n",
    "            dict_final_query = construct_dict(comb)\n",
    "            num_iter += 1\n",
    "            extracted_df = extract_rows_feature_set(df_filtered_final, dict_final_query)\n",
    "            if extracted_df.shape[0] != 0:\n",
    "                num_non_zero_combs += 1\n",
    "                results = compute_expected_succ_per_call_rate_feature_set(extracted_df, max_calls)\n",
    "                max_loc = compute_optimal_call_no(results)\n",
    "                if max_loc >= 0:\n",
    "                    combs_to_consider.append({'age':age_query, 'bal':bal_query, 'comb':comb, 'consider':True, 'max_loc':max_loc, 'rate':results[max_loc]['expected']})\n",
    "                else:\n",
    "                    combs_to_consider.append({'age':age_query, 'bal':bal_query, 'comb':comb, 'consider':False})\n",
    "#                 print(age_query)\n",
    "#                 print(bal_query)\n",
    "#                 print(dict_final_query)\n",
    "#                 print(\"Max Loc is: \", max_loc+1)\n",
    "#                 plot_graph_new(results, max_calls)\n",
    "#                 print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(df):\n",
    "    total_calls = 0\n",
    "    total_successes = 0\n",
    "    for loc, row in df.iterrows():\n",
    "        if row['y'] == \"yes\":\n",
    "            total_successes += 1\n",
    "        total_calls += row['campaign']\n",
    "    return div(total_successes, total_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All combs:  0.3513100131570743\n",
      "All combs(ratio >=0.20):  0.5514576239792396\n"
     ]
    }
   ],
   "source": [
    "# Metric using our method.\n",
    "filtered_combs_valid = [comb for comb in combs_to_consider if comb['consider'] == True]\n",
    "filtered_combs_valid_sorted = sorted(filtered_combs_valid, key=lambda k: k['rate'], reverse = True) \n",
    "print(\"All combs: \", mean([comb['rate'] for comb in combs_to_consider]))\n",
    "print(\"All combs(ratio >=0.20): \", mean([comb['rate'] for comb in combs_to_consider if comb['rate'] >= 0.20]))\n",
    "# The ratio will be increased further when we filter the unwanted feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04469269018705815\n"
     ]
    }
   ],
   "source": [
    "# Metric for the filtered dataset (only up to 20 calls).\n",
    "print(compute_metric(mkt_df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042326899068472104\n"
     ]
    }
   ],
   "source": [
    "# Metric for the entire dataset (up to 56 calls).\n",
    "print(compute_metric(mkt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section computes the metric for the purpose of determining the groupings within each feature (  ..... need to finish for the remainder of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_for_each_attribute(all_values, df, attrib):\n",
    "    for value in all_values:\n",
    "        v_query = \"{0} == '{1}'\".format(attrib, value)\n",
    "        print(v_query, compute_metric(mkt_df_filtered.query(v_query)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age >= 10 & age <= 19 0.14634146341463414\n",
      "age >= 20 & age <= 29 0.07631601041054488\n",
      "age >= 30 & age <= 39 0.040097307272879794\n",
      "age >= 40 & age <= 49 0.03357253501090633\n",
      "age >= 50 & age <= 59 0.03437390389337075\n",
      "age >= 60 & age <= 69 0.12427647259107934\n",
      "age >= 70 & age <= 79 0.20594965675057209\n",
      "age >= 80 0.1950354609929078\n"
     ]
    }
   ],
   "source": [
    "# Age.\n",
    "all_age_query_strings = ['age >= 10 & age <= 19', 'age >= 20 & age <= 29', 'age >= 30 & age <= 39', 'age >= 40 & age <= 49', 'age >= 50 & age <= 59','age >= 60 & age <= 69', 'age >= 70 & age <= 79', 'age >= 80']\n",
    "for age_query in all_age_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(age_query)\n",
    "    print(age_query, compute_metric(df_filtered_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job == 'student' 0.12907869481765835\n",
      "job == 'retired' 0.09875598086124401\n",
      "job == 'unemployed' 0.06631648063033486\n",
      "job == 'admin' 0.0\n",
      "job == 'management' 0.05079848502596541\n",
      "job == 'self-employed' 0.04410377358490566\n",
      "job == 'technician' 0.04040647274128299\n",
      "job == 'unknown' 0.0379041248606466\n",
      "job == 'services' 0.03470001880759827\n",
      "job == 'housemaid' 0.0319243275199527\n",
      "job == 'blue-collar' 0.02749087520385183\n",
      "job == 'entrepreneur' 0.030182090296832127\n"
     ]
    }
   ],
   "source": [
    "# Occupation.\n",
    "all_jobs = ['student', 'retired', 'unemployed', 'admin', 'management', 'self-employed', 'technician', 'unknown', 'services', 'housemaid', 'blue-collar', 'entrepreneur']\n",
    "compute_metric_for_each_attribute(all_jobs, mkt_df_filtered, 'job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital == 'married' 0.03762389773737097\n",
      "marital == 'single' 0.05973928537934915\n",
      "marital == 'unknown' 0.0\n"
     ]
    }
   ],
   "source": [
    "# Marital Status\n",
    "all_ms = ['married', 'single', 'unknown']\n",
    "compute_metric_for_each_attribute(all_ms, mkt_df_filtered, 'marital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education == 'tertiary' 0.05604090002528161\n",
      "education == 'secondary' 0.0410958904109589\n",
      "education == 'primary' 0.03222282905516111\n",
      "education == 'unknown' 0.05277486910994764\n"
     ]
    }
   ],
   "source": [
    "# Education\n",
    "all_ed = ['tertiary', 'secondary', 'primary', 'unknown']\n",
    "compute_metric_for_each_attribute(all_ed, mkt_df_filtered, 'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default == 'no' 0.04515566754107414\n",
      "default == 'yes' 0.021996615905245348\n",
      "default == 'unknown' 0.0\n"
     ]
    }
   ],
   "source": [
    "# Default\n",
    "all_def = ['no', 'yes', 'unknown']\n",
    "compute_metric_for_each_attribute(all_def, mkt_df_filtered, 'default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing == 'no' 0.061309197293838\n",
      "housing == 'yes' 0.030395519335452\n",
      "housing == 'unknown' 0.0\n"
     ]
    }
   ],
   "source": [
    "# Housing\n",
    "all_hs = ['no', 'yes', 'unknown']\n",
    "compute_metric_for_each_attribute(all_hs, mkt_df_filtered, 'housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan == 'no' 0.048405306237651706\n",
      "loan == 'yes' 0.025356992860142796\n",
      "loan == 'unknown' 0.0\n"
     ]
    }
   ],
   "source": [
    "# Loan\n",
    "all_ln = ['no', 'yes', 'unknown']\n",
    "compute_metric_for_each_attribute(all_ln, mkt_df_filtered, 'loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance >= -100000 & age <= -1 0.0\n",
      "balance >= 0 & balance < 1000 0.03984136840916789\n",
      "balance >= 1000 & balance < 2000 0.05351934051997464\n",
      "balance >= 2000 & balance < 3000 0.0680968858131488\n",
      "balance >= 3000 & balance < 4000 0.0689893862482695\n",
      "balance >= 4000 & balance < 5000 0.06461086637298091\n",
      "balance >= 5000 & balance < 6000 0.06534547402249598\n",
      "balance >= 6000 & balance < 7000 0.04906542056074766\n",
      "balance >= 7000 & balance < 8000 0.0671217292377702\n",
      "balance >= 8000 & balance < 9000 0.052269601100412656\n",
      "balance >= 9000 & balance < 10000 0.058823529411764705\n",
      "balance >= 10000 & balance < 11000 0.09217877094972067\n",
      "balance >= 11000 & balance < 12000 0.08365019011406843\n",
      "balance >= 12000 & balance < 13000 0.09821428571428571\n",
      "balance >= 13000 & balance < 14000 0.035897435897435895\n",
      "balance >= 14000 & balance < 15000 0.058823529411764705\n",
      "balance >= 15000 & balance < 16000 0.03418803418803419\n",
      "balance >= 16000 & balance < 17000 0.0\n",
      "balance >= 17000 & balance < 18000 0.028985507246376812\n",
      "balance >= 18000 & balance < 19000 0.11904761904761904\n",
      "balance >= 19000 & balance < 19000 0.0\n",
      "balance >= 20000 0.05742574257425743\n"
     ]
    }
   ],
   "source": [
    "# Balance\n",
    "all_bal_query_strings = ['balance >= -100000 & age <= -1', 'balance >= 0 & balance < 1000', 'balance >= 1000 & balance < 2000', 'balance >= 2000 & balance < 3000', 'balance >= 3000 & balance < 4000','balance >= 4000 & balance < 5000', 'balance >= 5000 & balance < 6000', 'balance >= 6000 & balance < 7000', 'balance >= 7000 & balance < 8000', 'balance >= 8000 & balance < 9000', 'balance >= 9000 & balance < 10000','balance >= 10000 & balance < 11000', 'balance >= 11000 & balance < 12000', 'balance >= 12000 & balance < 13000', 'balance >= 13000 & balance < 14000', 'balance >= 14000 & balance < 15000', 'balance >= 15000 & balance < 16000', 'balance >= 16000 & balance < 17000','balance >= 17000 & balance < 18000', 'balance >= 18000 & balance < 19000', 'balance >= 19000 & balance < 19000', 'balance >= 20000']\n",
    "for bal_query in all_bal_query_strings:\n",
    "    df_filtered_final = mkt_df_filtered.query(bal_query)\n",
    "    print(bal_query, compute_metric(df_filtered_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
